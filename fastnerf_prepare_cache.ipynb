{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72376910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86773c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdf.netowrk import SqueezeSDFNetwork as SDFNetwork "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d991f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SDFNetwork(encoding=\"hashgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6838acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fe7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_fn():\n",
    "    return 1\n",
    "\n",
    "checkpoint_list = sorted(glob.glob(f'trial_sdf/checkpoints/ngp_ep0161.pth.tar'))\n",
    "if checkpoint_list:\n",
    "    checkpoint = checkpoint_list[-1]\n",
    "checkpoint_dict = torch.load(checkpoint, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_keys, unexpected_keys = model.load_state_dict(checkpoint_dict['model'], strict=False)\n",
    "missing_keys, unexpected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fdd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 1\n",
    "N = 512\n",
    "x_ = np.linspace(-bound, bound, N)\n",
    "y_ = np.linspace(-bound, bound, N)\n",
    "z_ = np.linspace(-bound, bound, N)\n",
    "x, y = np.meshgrid(x_, y_, indexing='ij')\n",
    "XY = np.stack([x, y], axis=-1).reshape((-1, 2))\n",
    "x, y, z = np.meshgrid(x_, y_, z_, indexing='ij')\n",
    "X = np.stack([x, y, z], axis=-1).reshape((-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82720c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "batch = 2**16\n",
    "encoders = [model.encoder_xy, model.encoder_yz, model.encoder_zx]\n",
    "backbones = [model.backbone_xy, model.backbone_yz, model.backbone_zx]\n",
    "names = [\"xy\", \"yz\", \"zx\"]\n",
    "for encoder, backbone, name in zip(encoders, backbones, names):\n",
    "    results = []\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        for k in tqdm(range(int(XY.shape[0] / batch))):\n",
    "            X = torch.tensor(XY[k * batch:(k + 1) * batch].astype(np.float32)).to(device)\n",
    "            h = model.forward_backbone(X, backbone, encoder)\n",
    "            results.append(h.detach().cpu().numpy())\n",
    "    results_ = np.vstack(results).reshape([N, N, -1])    \n",
    "    with open(f\"cache_{name}_32_p1.npy\", \"wb\") as f:\n",
    "        np.save(f, results_[:, :, :4].astype(np.float32), allow_pickle=False)\n",
    "    with open(f\"cache_{name}_32_p2.npy\", \"wb\") as f:\n",
    "        np.save(f, results_[:, :, 4:].astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "batch = 2**16\n",
    "results = []\n",
    "with torch.cuda.amp.autocast(enabled=True):\n",
    "    for k in tqdm(range(int(X.shape[0] / batch))):\n",
    "        x = torch.tensor(X[k * batch:(k + 1) * batch].astype(np.float32)).to(device)\n",
    "        xy = x[:, [0, 1]]\n",
    "        yz = x[:, [1, 2]]\n",
    "        zx = x[:, [2, 0]]\n",
    "\n",
    "        h_xy = model.forward_backbone(xy, model.backbone_xy, model.encoder_xy)\n",
    "        h_yz = model.forward_backbone(yz, model.backbone_yz, model.encoder_yz)\n",
    "        h_zx = model.forward_backbone(zx, model.backbone_zx, model.encoder_zx)\n",
    "\n",
    "        h1 = (h_xy * h_yz).sum(1)[:, None]\n",
    "        h2 = (h_yz * h_zx).sum(1)[:, None]\n",
    "        h3 = (h_zx * h_xy).sum(1)[:, None]\n",
    "\n",
    "\n",
    "        h = torch.cat([h1, h2, h3], dim=1)\n",
    "\n",
    "        h = model.head(h)\n",
    "        results.append(h.detach().cpu().numpy())\n",
    "    results_ = np.vstack(results).reshape([N, N, -1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf34c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scaled =np.clip(np.interp(\n",
    "        results_, (0, results_.max()), (0, 255)).astype(\"uint8\"), 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for i in tqdm(range(512)):\n",
    "    a = results_scaled[:, i, :]\n",
    "    img = Image.fromarray(np.stack([a, a, a], axis=2), 'RGB')\n",
    "    img.save(f'cache_sdf\\img{i}.png')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7831225",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.head.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# w, h = 512, 512\n",
    "data = results_[:, :, :3]\n",
    "# data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
    "img = Image.fromarray(np.interp(data, (data.min(), data.max()),(0, 255)).astype(\"uint8\"), 'RGB')\n",
    "# img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712273da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a65d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def spherical_to_cartesian(r, theta, phi):\n",
    "    x = r * math.sin(theta) * math.cos(phi)\n",
    "    y = r * math.sin(theta) * math.sin(phi)\n",
    "    z = r * math.cos(theta)\n",
    "    return (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = opt.bound\n",
    "N = 2048\n",
    "theta_ = np.linspace(0, 1 , N) ** 1 * np.pi\n",
    "phi_ = np.linspace(0, 1, N) ** 1 * 2 * np.pi\n",
    "theta, phi = np.meshgrid(theta_, phi_, indexing='ij')\n",
    "x = np.sin(theta) * np.cos(phi);\n",
    "z = np.sin(theta) * np.sin(phi);\n",
    "y = np.cos(theta);\n",
    "D = np.stack([x, y, z], axis=-1).reshape((-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = opt.bound\n",
    "N = 2048\n",
    "theta_ = np.linspace(0, 1 , N) ** 1 * np.pi\n",
    "phi_ = np.linspace(0, 1, N) ** 1 * 2 * np.pi\n",
    "theta, phi = np.meshgrid(theta_, phi_, indexing='ij')\n",
    "\n",
    "\n",
    "\n",
    "x = np.sin(theta) * np.cos(phi);\n",
    "y = np.sin(theta) * np.sin(phi);\n",
    "z = np.cos(theta);\n",
    "D = np.stack([x, y, z], axis=-1).reshape((-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xyz -> yzx\n",
    "theta = torch.acos(d[:, 1])\n",
    "phi = torch.atan2(d[:, 2], d[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c65fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Helix equation\n",
    "t = np.linspace(0, 10, 50)\n",
    "# x, y, z = np.cos(t), np.sin(t), t\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x.flatten(), y=y.flatten(), z=z.flatten(),\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(size=0.2,)\n",
    "                                  )])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(X[:10].astype(np.float16)).to(device).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6191cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f476fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.cuda.amp.autocast(enabled=True):\n",
    "    for k in tqdm(range(int(X.shape[0] / batch))):\n",
    "        x = torch.tensor(X[k * batch:(k + 1) * batch].astype(np.float32)).to(device)\n",
    "        x_ = torch.floor(x / (2 * model.bound / model.resolution)) + model.resolution // 2\n",
    "        x_ = torch.clamp(x_, 0, model.resolution - 1)\n",
    "        c = (x_ - model.resolution // 2 + 0.5) * (2 * model.bound / model.resolution)\n",
    "\n",
    "        x_ = x_[:, 0] * model.resolution * model.resolution + x_[:, 1] * model.resolution + x_[:, 2]\n",
    "        bids = x_.int()\n",
    "        result = torch.zeros((x.shape[0], 8)).half()\n",
    "        for bid in torch.unique(bids):\n",
    "            pos = x[x_ == bid]\n",
    "            centers = c[x_ == bid]\n",
    "            h = model.encoders[bid](pos - centers, bound=model.bound / model.resolution)\n",
    "            for l in model.sigma_nets[bid]:\n",
    "                h = l(h)\n",
    "            result[x_ == bid] = h.detach().cpu()      \n",
    "        results.append(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.cuda.amp.autocast(enabled=True):\n",
    "    for k in tqdm(range(int(X.shape[0] / batch))):\n",
    "        h = model.encoder(torch.tensor(X[k * batch:(k + 1) * batch].astype(np.float32)).to(device))\n",
    "        for l in model.sigma_net:\n",
    "            h = l(h)\n",
    "            \n",
    "        results.append(h.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c043b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32545856",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pos = np.vstack(results).reshape([512, 512, 512, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935c375",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_pos.npy\", \"wb\") as f:\n",
    "    np.save(f, results_pos, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_pos_32.npy\", \"wb\") as f:\n",
    "    np.save(f, results_pos.astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03403b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_pos_32_p1.npy\", \"wb\") as f:\n",
    "    np.save(f, results_pos[:, :, :, :4].astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f21f44",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_pos_32_p2.npy\", \"wb\") as f:\n",
    "    np.save(f, results_pos[:, :, :,4:].astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab832c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(data, 'RGB')\n",
    "img.save('my.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "np.interp(results_pos[i, :, :, :4], (results_pos.min(), results_pos.max()), (0, 255)).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pos_scaled = np.interp(\n",
    "        results_pos, (results_pos.min(), results_pos.max()), (0, 255)).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for i in tqdm(range(512)):\n",
    "    img = Image.fromarray(results_pos_scaled[:, :, i, :3], 'RGB')\n",
    "    img.save(f'cache_pos_p1_slices_z\\cache_pos_32_p1_{i}.png')\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = []\n",
    "with torch.cuda.amp.autocast(enabled=True):\n",
    "    for k in tqdm(range(int(D.shape[0] / batch))):\n",
    "        d = torch.tensor(D[k * batch:(k + 1) * batch].astype(np.float32)).to(device)\n",
    "\n",
    "        x_ = x_[:, 0] * model.resolution * model.resolution + x_[:, 1] * model.resolution + x_[:, 2]\n",
    "        bids = x_.int()\n",
    "        result = torch.zeros((x.shape[0], 8)).half()\n",
    "        for bid in torch.unique(bids):\n",
    "            pos = x[x_ == bid]\n",
    "            centers = c[x_ == bid]\n",
    "            h = model.encoders[bid](pos - centers, bound=model.bound / model.resolution)\n",
    "            for l in model.sigma_nets[bid]:\n",
    "                h = l(h)\n",
    "            result[x_ == bid] = h.detach().cpu()      \n",
    "        results.append(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = []\n",
    "with torch.cuda.amp.autocast(enabled=True):\n",
    "    for k in tqdm(range(int(D.shape[0] / batch))):\n",
    "        h = model.encoder_dir(torch.tensor(D[k * batch:(k + 1) * batch].astype(np.float32)).to(device))\n",
    "        for l in model.gamma_net:\n",
    "            h = l(h)\n",
    "            \n",
    "        results_dir.append(h.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b25c88",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[-0.2913,  0.5830,  0.2158,  ..., -0.2471, -1.0830, -1.0264],\n",
    "        [-0.2959,  0.5845,  0.2192,  ..., -0.2418, -1.0820, -1.0234],\n",
    "        [-0.2959,  0.5845,  0.2192,  ..., -0.2418, -1.0820, -1.0234],\n",
    "        ...,\n",
    "        [-0.4473,  0.5923,  0.4666,  ...,  0.1472, -1.0771, -0.7944],\n",
    "        [-0.4473,  0.5918,  0.4678,  ...,  0.1487, -1.0771, -0.7935],\n",
    "        [-0.4478,  0.5913,  0.4690,  ...,  0.1504, -1.0781, -0.7925]],\n",
    "       device='cuda:0')\n",
    "```\n",
    "```\n",
    "tensor([[ 0.2699, -0.8343, -0.4807],\n",
    "        [ 0.2702, -0.8351, -0.4791],\n",
    "        [ 0.2705, -0.8359, -0.4776],\n",
    "        ...,\n",
    "        [ 0.2910, -0.9562,  0.0311],\n",
    "        [ 0.2910, -0.9562,  0.0334],\n",
    "        [ 0.2909, -0.9561,  0.0356]], device='cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_ = np.vstack(results_dir).reshape([N, N, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor([[ 0.2699, -0.8343, -0.4807],\n",
    "        [ 0.2702, -0.8351, -0.4791],\n",
    "        [ 0.2705, -0.8359, -0.4776]])\n",
    "theta = torch.acos(d[:, 1])\n",
    "theta = theta / torch.pi\n",
    "phi = torch.atan2(-d[:, 2], -d[:, 0])\n",
    "phi = (phi + torch.pi) / (2 * torch.pi)\n",
    "d = torch.stack((theta , phi), dim=-1)\n",
    "\n",
    "gamma_index = torch.round(d * (results_dir_.shape[0] - 1)).long()\n",
    "gamma = results_dir_[gamma_index[:, 0], gamma_index[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(\n",
    "    np.logical_and(\n",
    "        np.logical_and(\n",
    "            np.isclose(results_dir_[:, :, 0], 0.0781, rtol=1e-2),\n",
    "            np.isclose(results_dir_[:, :, 1], 0.8110, rtol=1e-2), \n",
    "            np.isclose(results_dir_[:, :, 2], -0.9033, rtol=1e-2)\n",
    "        ),\n",
    "        np.logical_and(\n",
    "            np.isclose(results_dir_[:, :, 5], 0.3992, rtol=1e-2),\n",
    "            np.isclose(results_dir_[:, :, 6], -1.5908, rtol=1e-2), \n",
    "            np.isclose(results_dir_[:, :, 7], -0.0550, rtol=1e-2)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor([[ 0.2699, -0.8343, -0.4807],\n",
    "        [ 0.2702, -0.8351, -0.4791],\n",
    "        [ 0.2705, -0.8359, -0.4776]])\n",
    "torch.atan2(d[:, 0], d[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1702 / 2048) * 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_[1656][1699]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644496e",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 0.2699, -0.8343, -0.4807],\n",
    "        [ 0.2702, -0.8351, -0.4791],\n",
    "        [ 0.2705, -0.8359, -0.4776],\n",
    "        ...,\n",
    "        [ 0.2911, -0.9567, -0.0058],\n",
    "        [ 0.2911, -0.9567, -0.0035],\n",
    "        [ 0.2911, -0.9567, -0.0012]], device='cuda:0')\n",
    "```\n",
    "```\n",
    "tensor([[ 0.0781,  0.8110, -0.9033,  ...,  0.3992, -1.5908, -0.0550],\n",
    "        [ 0.0784,  0.8101, -0.9062,  ...,  0.3965, -1.5908, -0.0547],\n",
    "        [ 0.0789,  0.8096, -0.9082,  ...,  0.3928, -1.5898, -0.0551],\n",
    "        ...,\n",
    "        [ 0.0867,  0.6597, -0.8677,  ..., -0.3740, -1.3115,  0.0590],\n",
    "        [ 0.0874,  0.6587, -0.8662,  ..., -0.3765, -1.3115,  0.0596],\n",
    "        [ 0.0883,  0.6577, -0.8662,  ..., -0.3799, -1.3115,  0.0610]],\n",
    "       device='cuda:0', dtype=torch.float16)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca1f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34668fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(results_dir).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_ = np.vstack(results_dir).reshape([N, N, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d77ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_dir.npy\", \"wb\") as f:\n",
    "    np.save(f, results_dir_, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56211c60",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_dir_32.npy\", \"wb\") as f:\n",
    "    np.save(f, results_dir_.astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee5697",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_dir_32_p1.npy\", \"wb\") as f:\n",
    "    np.save(f, results_dir_[:, :, :4].astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571482d",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(\"cache_dir_32_p2.npy\", \"wb\") as f:\n",
    "    np.save(f, results_dir_[:, :, 4:].astype(np.float32), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(value, leftMin, leftMax, rightMin, rightMax):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# w, h = 512, 512\n",
    "data = results_dir_[:, :, :3]\n",
    "# data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
    "img = Image.fromarray(np.interp(data, (data.min(), data.max()),(0, 255)).astype(\"uint8\"), 'RGB')\n",
    "# img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bbba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
